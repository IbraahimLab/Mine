{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4bb6cea306ec42d8860a9a3e633b7590": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3310178f98f4c7aa45a824f06c2c4cd",
              "IPY_MODEL_3e71b7e59e5d483694a1bdd234b7ce87",
              "IPY_MODEL_3f0e4425f2b040da889236c8bacc4bc3"
            ],
            "layout": "IPY_MODEL_1bb1c9b038044518a9f7a76437cd83d9"
          }
        },
        "f3310178f98f4c7aa45a824f06c2c4cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15e7dad0222840688ad4583a3d5bb82a",
            "placeholder": "​",
            "style": "IPY_MODEL_bcece90535224a34811f7aa62a82f1b2",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "3e71b7e59e5d483694a1bdd234b7ce87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ae193da7dfa4ba1af1dccdc3f19661e",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b2218b6d4f1549b39c97e547ccbbc4d2",
            "value": 26
          }
        },
        "3f0e4425f2b040da889236c8bacc4bc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e80f23ddcbc14225a601504bbfa36f51",
            "placeholder": "​",
            "style": "IPY_MODEL_e6d4a7569895458188d26a002d319458",
            "value": " 26.0/26.0 [00:00&lt;00:00, 910B/s]"
          }
        },
        "1bb1c9b038044518a9f7a76437cd83d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15e7dad0222840688ad4583a3d5bb82a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcece90535224a34811f7aa62a82f1b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ae193da7dfa4ba1af1dccdc3f19661e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2218b6d4f1549b39c97e547ccbbc4d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e80f23ddcbc14225a601504bbfa36f51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6d4a7569895458188d26a002d319458": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4b8c99164cb40a3b478ea8aa0123939": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80f2f4d3457442e3b48536414700313d",
              "IPY_MODEL_a1f0df74af8644c8b9ce684fc135d06d",
              "IPY_MODEL_972145f9ee9246869507916b1fbd238c"
            ],
            "layout": "IPY_MODEL_791a190d19a54807807d7ee63a682dcd"
          }
        },
        "80f2f4d3457442e3b48536414700313d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddf373b77b7d434caae2163051d1a272",
            "placeholder": "​",
            "style": "IPY_MODEL_9ca71b2cad244f4ab0f26dc7ddf77517",
            "value": "vocab.json: 100%"
          }
        },
        "a1f0df74af8644c8b9ce684fc135d06d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e69798294e184d9e9601261e91c1b0cc",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa8691baf74649229c64bb70fdbdfd62",
            "value": 1042301
          }
        },
        "972145f9ee9246869507916b1fbd238c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78078830dbe4446686dbc7aba49891fa",
            "placeholder": "​",
            "style": "IPY_MODEL_0f77484b3b2b4915be28d045fca82d9c",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 1.70MB/s]"
          }
        },
        "791a190d19a54807807d7ee63a682dcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddf373b77b7d434caae2163051d1a272": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ca71b2cad244f4ab0f26dc7ddf77517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e69798294e184d9e9601261e91c1b0cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa8691baf74649229c64bb70fdbdfd62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78078830dbe4446686dbc7aba49891fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f77484b3b2b4915be28d045fca82d9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a10f7d5cff64faeb2455f918c309e77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d4c598bf2d249109af692048263071e",
              "IPY_MODEL_5a70a614608548489688a08b6c05921a",
              "IPY_MODEL_841e3593fa804e23ae2eb1e306b0e316"
            ],
            "layout": "IPY_MODEL_f89705b99b0943d6bd7fefa08710e12e"
          }
        },
        "4d4c598bf2d249109af692048263071e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d57e6bf950104e828e2dd5c9f63e14f8",
            "placeholder": "​",
            "style": "IPY_MODEL_1240f06bb2fd40489c6f33b29b99fd27",
            "value": "merges.txt: 100%"
          }
        },
        "5a70a614608548489688a08b6c05921a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0b79d3a153a4900bf8114cdca4fc363",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0234d1e0ec304b83b5c3a0142fba7a16",
            "value": 456318
          }
        },
        "841e3593fa804e23ae2eb1e306b0e316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b5eb60313ee4b549fc02750e8e82b9e",
            "placeholder": "​",
            "style": "IPY_MODEL_39eb369bc5814bfca38f4f9812e63a28",
            "value": " 456k/456k [00:00&lt;00:00, 1.38MB/s]"
          }
        },
        "f89705b99b0943d6bd7fefa08710e12e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d57e6bf950104e828e2dd5c9f63e14f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1240f06bb2fd40489c6f33b29b99fd27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0b79d3a153a4900bf8114cdca4fc363": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0234d1e0ec304b83b5c3a0142fba7a16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b5eb60313ee4b549fc02750e8e82b9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39eb369bc5814bfca38f4f9812e63a28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8862a686eb7d44929cf981a98d487cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc4ee41a0e0f449e922c28acfeac8198",
              "IPY_MODEL_5d4703e794b945339a32e0d79267f3be",
              "IPY_MODEL_0306d53e19e148fca4fc7612b7e8e7ab"
            ],
            "layout": "IPY_MODEL_f1d3b7d04a20402dba260f40d10bccf2"
          }
        },
        "bc4ee41a0e0f449e922c28acfeac8198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_809dcab82a7b40ffb942c92880ef449c",
            "placeholder": "​",
            "style": "IPY_MODEL_224d8f9f19084590bcf6f12a6806c7af",
            "value": "tokenizer.json: 100%"
          }
        },
        "5d4703e794b945339a32e0d79267f3be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d244c610ad14674a9b51035049fe5c4",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80fb3f79de3e4983bb439ae7bbb47ced",
            "value": 1355256
          }
        },
        "0306d53e19e148fca4fc7612b7e8e7ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5eb4871c3e7d4ba8b892508eaf56868e",
            "placeholder": "​",
            "style": "IPY_MODEL_d023c417ebb44670a666addda093d5b7",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 11.9MB/s]"
          }
        },
        "f1d3b7d04a20402dba260f40d10bccf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "809dcab82a7b40ffb942c92880ef449c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "224d8f9f19084590bcf6f12a6806c7af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d244c610ad14674a9b51035049fe5c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80fb3f79de3e4983bb439ae7bbb47ced": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5eb4871c3e7d4ba8b892508eaf56868e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d023c417ebb44670a666addda093d5b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284,
          "referenced_widgets": [
            "4bb6cea306ec42d8860a9a3e633b7590",
            "f3310178f98f4c7aa45a824f06c2c4cd",
            "3e71b7e59e5d483694a1bdd234b7ce87",
            "3f0e4425f2b040da889236c8bacc4bc3",
            "1bb1c9b038044518a9f7a76437cd83d9",
            "15e7dad0222840688ad4583a3d5bb82a",
            "bcece90535224a34811f7aa62a82f1b2",
            "6ae193da7dfa4ba1af1dccdc3f19661e",
            "b2218b6d4f1549b39c97e547ccbbc4d2",
            "e80f23ddcbc14225a601504bbfa36f51",
            "e6d4a7569895458188d26a002d319458",
            "a4b8c99164cb40a3b478ea8aa0123939",
            "80f2f4d3457442e3b48536414700313d",
            "a1f0df74af8644c8b9ce684fc135d06d",
            "972145f9ee9246869507916b1fbd238c",
            "791a190d19a54807807d7ee63a682dcd",
            "ddf373b77b7d434caae2163051d1a272",
            "9ca71b2cad244f4ab0f26dc7ddf77517",
            "e69798294e184d9e9601261e91c1b0cc",
            "aa8691baf74649229c64bb70fdbdfd62",
            "78078830dbe4446686dbc7aba49891fa",
            "0f77484b3b2b4915be28d045fca82d9c",
            "6a10f7d5cff64faeb2455f918c309e77",
            "4d4c598bf2d249109af692048263071e",
            "5a70a614608548489688a08b6c05921a",
            "841e3593fa804e23ae2eb1e306b0e316",
            "f89705b99b0943d6bd7fefa08710e12e",
            "d57e6bf950104e828e2dd5c9f63e14f8",
            "1240f06bb2fd40489c6f33b29b99fd27",
            "d0b79d3a153a4900bf8114cdca4fc363",
            "0234d1e0ec304b83b5c3a0142fba7a16",
            "7b5eb60313ee4b549fc02750e8e82b9e",
            "39eb369bc5814bfca38f4f9812e63a28",
            "8862a686eb7d44929cf981a98d487cc1",
            "bc4ee41a0e0f449e922c28acfeac8198",
            "5d4703e794b945339a32e0d79267f3be",
            "0306d53e19e148fca4fc7612b7e8e7ab",
            "f1d3b7d04a20402dba260f40d10bccf2",
            "809dcab82a7b40ffb942c92880ef449c",
            "224d8f9f19084590bcf6f12a6806c7af",
            "5d244c610ad14674a9b51035049fe5c4",
            "80fb3f79de3e4983bb439ae7bbb47ced",
            "5eb4871c3e7d4ba8b892508eaf56868e",
            "d023c417ebb44670a666addda093d5b7"
          ]
        },
        "collapsed": true,
        "id": "o_u8i1EtMHGf",
        "outputId": "669319fa-12d1-435e-983b-25dc065578cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4bb6cea306ec42d8860a9a3e633b7590"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4b8c99164cb40a3b478ea8aa0123939"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a10f7d5cff64faeb2455f918c309e77"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8862a686eb7d44929cf981a98d487cc1"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from transformers import GPT2TokenizerFast\n",
        "\n",
        "# Use GPT-2 tokeniser so we don't have to build one from scratch yet.\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
        "vocab_size = tokenizer.vocab_size\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----"
      ],
      "metadata": {
        "id": "XYQVQE-TNeIC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This code sets up some basic tools for working with numbers and text in a computer program.\n",
        "\n",
        "*   **`import math`**: This line brings in a collection of math tools, like how to calculate square roots.\n",
        "*   **`import torch`**: This brings in a big tool called 'PyTorch,' which is good for making smart computer programs (like AI).\n",
        "*   **`import torch.nn as nn`**: This part of PyTorch helps build the 'brain' (neural network) for our smart program.\n",
        "*   **`import torch.nn.functional as F`**: These are more useful functions for the 'brain' of our program.\n",
        "*   **`from transformers import GPT2TokenizerFast`**: This line gets a special tool from a library called 'transformers.' This tool helps break sentences into words or parts.\n",
        "*   **`tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")`**: This makes a tool that knows how to break text into pieces just like the famous 'GPT2' program does.\n",
        "*   **`vocab_size = tokenizer.vocab_size`**: This finds out how many different unique words or pieces of words the 'GPT2' tool understands. It's like counting all the words in its dictionary."
      ],
      "metadata": {
        "id": "T9kP0dGLNcaj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----"
      ],
      "metadata": {
        "id": "DKV0Quv_Nhlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model shape\n",
        "block_size = 128     # max context length (how many tokens the model can \"see\")\n",
        "n_embd     = 256     # embedding size (vector size for each token)\n",
        "n_head     = 8       # attention heads\n",
        "n_layer    = 4       # number of transformer blocks\n",
        "dropout    = 0.1\n",
        "\n",
        "# Training\n",
        "batch_size = 8\n",
        "lr         = 3e-4\n",
        "steps      = 2000\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
      ],
      "metadata": {
        "id": "hDBpU90sMPjP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\n",
        "This part of the code sets up some important numbers that control how our smart computer program (the AI model) will be built and trained.\n",
        "\n",
        "### Model Shape (How the AI is Built):\n",
        "*   **`block_size = 128`**: This means the AI can look at 128 pieces of text (tokens) at a time to understand what's happening. It's like its short-term memory length.\n",
        "*   **`n_embd = 256`**: Each piece of text (token) will be turned into a special code (vector) that is 256 numbers long. This helps the computer understand the meaning of each token.\n",
        "*   **`n_head = 8`**: Our AI has 8 different 'attention' parts. Each part helps the AI focus on different important words in the text at the same time.\n",
        "*   **`n_layer = 4`**: The AI has 4 main layers, like levels in a building. Each layer helps process information more deeply.\n",
        "*   **`dropout = 0.1`**: This is a trick to make the AI smarter. During training, 10% of the connections in the AI's 'brain' are randomly turned off. This prevents the AI from relying too much on any single connection.\n",
        "\n",
        "### Training (How the AI Learns):\n",
        "*   **`batch_size = 8`**: The AI will learn by looking at 8 examples (batches) of text at once before updating its knowledge.\n",
        "*   **`lr = 3e-4`**: This is the 'learning rate.' It's a small number (0.0003) that tells the AI how big of a step to take when adjusting its knowledge during learning.\n",
        "*   **`steps = 2000`**: The AI will go through the learning process 2000 times.\n",
        "\n",
        "### Device (Where the AI Runs):\n",
        "*   **`device = \"cuda\" if torch.cuda.is_available() else \"cpu\"`**: This checks if your computer has a special fast chip called a 'GPU' (often called 'cuda' for NVIDIA GPUs). If it does, the AI will use that to learn much faster. If not, it will use the main computer chip ('cpu').\n",
        "\n",
        "-----"
      ],
      "metadata": {
        "id": "dspzSE_gNMzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read text\n",
        "with open(\"/content/xasan.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "# Convert to token IDs\n",
        "data = torch.tensor(tokenizer.encode(text), dtype=torch.long)\n",
        "\n",
        "# Train/val split\n",
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n]\n",
        "val_data   = data[n:]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPL2eie7Me2E",
        "outputId": "07fb230e-195b-4575-cb68-788fbcc55598"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (7449 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e28a4c5f"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLE3vfx1OCmW"
      },
      "source": [
        "---\n",
        "\n",
        "This code is about getting the text ready for our AI model to learn from.\n",
        "\n",
        "### Reading and Preparing Text:\n",
        "*   **`with open(\"/content/xasan.txt\", \"r\", encoding=\"utf-8\") as f: text = f.read()`**: This line opens a file named \"xasan.txt\" from your computer, reads all the words inside it, and puts them into a variable called `text`.\n",
        "*   **`data = torch.tensor(tokenizer.encode(text), dtype=torch.long)`**: Here, the AI's special `tokenizer` (the tool we set up earlier) breaks down all the words in `text` into numbers. These numbers are like a secret code that the computer understands. Then, these numbers are stored as `data` in a special format called a `torch.tensor`.\n",
        "\n",
        "### Splitting Data for Learning and Testing:\n",
        "*   **`n = int(0.9 * len(data))`**: This calculates a point, `n`, which is 90% of the way through our `data` (the list of numbers).\n",
        "*   **`train_data = data[:n]`**: The first 90% of the data is put into `train_data`. This is the part the AI will use to learn.\n",
        "*   **`val_data = data[n:]`**: The last 10% of the data is put into `val_data`. This is the part the AI will use to test itself, to see how well it has learned without ever having seen this part before."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z_EG0UeROYhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(split: str):\n",
        "    source = train_data if split == \"train\" else val_data\n",
        "\n",
        "    # Random starting positions\n",
        "    ix = torch.randint(0, len(source) - block_size - 1, (batch_size,))\n",
        "\n",
        "    # Build batch by slicing\n",
        "    x = torch.stack([source[i : i + block_size] for i in ix])\n",
        "    y = torch.stack([source[i + 1 : i + 1 + block_size] for i in ix])\n",
        "\n",
        "    return x.to(device), y.to(device)\n"
      ],
      "metadata": {
        "id": "3dau69wmOOLz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What this function does (simple explanation)\n",
        "\n",
        "- Picks either the **training** data or the **validation** data based on the input.\n",
        "- Randomly chooses several starting positions in the data.\n",
        "- From each position, it takes a short continuous chunk of tokens.\n",
        "- These chunks become the **input batch**.\n",
        "- The **target batch** is the same chunks, but shifted one step forward.\n",
        "- Both inputs and targets are moved to the chosen device (CPU or GPU).\n",
        "- Returns the input–target pair ready for model training.\n"
      ],
      "metadata": {
        "id": "Y--b90zLOzeM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------"
      ],
      "metadata": {
        "id": "pQj2lMuyO_7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CausalSelfAttention(nn.Module):\n",
        "    def __init__(self, n_embd, n_head, block_size, dropout):\n",
        "        super().__init__()\n",
        "        assert n_embd % n_head == 0\n",
        "\n",
        "        self.n_head = n_head\n",
        "        self.head_dim = n_embd // n_head\n",
        "\n",
        "        # One layer to produce Q, K, V together\n",
        "        self.qkv = nn.Linear(n_embd, 3 * n_embd)\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "\n",
        "        # Causal mask: lower-triangular matrix\n",
        "        mask = torch.tril(torch.ones(block_size, block_size))\n",
        "        self.register_buffer(\"mask\", mask)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape  # Batch, Time, Channels(=n_embd)\n",
        "\n",
        "        qkv = self.qkv(x)                       # (B, T, 3C)\n",
        "        q, k, v = qkv.split(C, dim=2)           # each (B, T, C)\n",
        "\n",
        "        # reshape into heads: (B, n_head, T, head_dim)\n",
        "        q = q.view(B, T, self.n_head, self.head_dim).transpose(1, 2)\n",
        "        k = k.view(B, T, self.n_head, self.head_dim).transpose(1, 2)\n",
        "        v = v.view(B, T, self.n_head, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        # attention scores: (B, n_head, T, T)\n",
        "        att = (q @ k.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "\n",
        "        # apply causal mask (only allow looking backward)\n",
        "        att = att.masked_fill(self.mask[:T, :T] == 0, float(\"-inf\"))\n",
        "\n",
        "        # softmax -> probabilities\n",
        "        att = F.softmax(att, dim=-1)\n",
        "        att = self.drop(att)\n",
        "\n",
        "        # weighted sum of values -> (B, n_head, T, head_dim)\n",
        "        out = att @ v\n",
        "\n",
        "        # merge heads back: (B, T, C)\n",
        "        out = out.transpose(1, 2).contiguous().view(B, T, C)\n",
        "        out = self.drop(self.proj(out))\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "am0q-wzhObYT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0_WK8J0YO_RE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "230bea52"
      },
      "source": [
        "---\n",
        "\n",
        "This code defines a special part of our AI's 'brain' called `CausalSelfAttention`. Think of it like this:\n",
        "\n",
        "Imagine the AI is reading a sentence. When it tries to understand a word, it doesn't just look at that word; it looks at *all the words before it* to get context. This `CausalSelfAttention` mechanism helps the AI figure out how important each previous word is to the current word it's focusing on.\n",
        "\n",
        "### How it works (simplified):\n",
        "\n",
        "**`__init__` (Setting things up):**\n",
        "*   It gets details like the size of the word codes (`n_embd`), how many 'focus points' the AI has (`n_head`), how many words it can look back at (`block_size`), and a `dropout` value to prevent overthinking.\n",
        "*   It creates special layers (`qkv`, `proj`, `drop`) that help transform the word codes.\n",
        "*   It prepares a 'mask' (`self.register_buffer(\"mask\", mask)`) that makes sure the AI *only* looks at words that came before the current word, not future words. This is what 'causal' means – it respects the order of events.\n",
        "\n",
        "**`forward` (Processing the words):**\n",
        "*   **Input `x`**: This is the batch of words (as numerical codes) the AI is currently processing.\n",
        "*   **`q, k, v = qkv.split(C, dim=2)`**: The input words are first transformed into three different versions: 'query' (Q), 'key' (K), and 'value' (V). Think of Q as what you're looking for, K as what's available, and V as the actual information.\n",
        "*   **`q = q.view(...)`, `k = k.view(...)`, `v = v.view(...)`**: These lines rearrange the Q, K, V versions so that each of the AI's 'focus points' (`n_head`) can work on them independently.\n",
        "*   **`att = (q @ k.transpose(-2, -1)) / math.sqrt(self.head_dim)`**: This is where the AI calculates 'attention scores'. It compares each 'query' (Q) with all the 'keys' (K) of previous words. The higher the score, the more relevant that previous word is.\n",
        "*   **`att = att.masked_fill(...)`**: This applies the 'causal mask' to ensure the AI doesn't accidentally look at words that come *after* the current word.\n",
        "*   **`att = F.softmax(att, dim=-1)`**: The attention scores are turned into probabilities, so they sum up to 1. This means the AI has a clear idea of how much 'attention' to give to each previous word.\n",
        "*   **`out = att @ v`**: The AI then takes a weighted average of the 'values' (V) of the previous words, using the calculated attention probabilities. This creates a new, enriched representation of the current word, incorporating relevant context.\n",
        "*   **`out = out.transpose(...)`**: Finally, the results from all the independent 'focus points' are combined back together.\n",
        "*   **`out = self.drop(self.proj(out))`**: The combined result is passed through a final layer and dropout, producing the output for this attention step.\n",
        "\n",
        "In essence, this block helps the AI intelligently combine information from earlier parts of the text to better understand the current part, but *only* from the past, not the future."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------"
      ],
      "metadata": {
        "id": "YD2qcsQLPeWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, n_embd, dropout):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n"
      ],
      "metadata": {
        "id": "QkOFqQsIPe8i"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd146a38"
      },
      "source": [
        "---\n",
        "\n",
        "This code defines another important building block for our AI's 'brain' called `FeedForward`.\n",
        "\n",
        "After the AI has used its 'attention' (from `CausalSelfAttention`) to understand how different words relate to each other, this `FeedForward` part helps it think more deeply about each individual word's meaning.\n",
        "\n",
        "### How it works (simplified):\n",
        "\n",
        "**`__init__` (Setting things up):**\n",
        "*   It takes in the size of the word codes (`n_embd`) and a `dropout` value.\n",
        "*   It creates a sequence of layers (`self.net`) that will process the word codes:\n",
        "    *   **`nn.Linear(n_embd, 4 * n_embd)`**: This is like a 'thought expander'. It takes the word's code and makes it much longer (4 times its original size). This gives the AI more room to process complex ideas about the word.\n",
        "    *   **`nn.GELU()`**: This is a special 'thinking' step that adds non-linearity, allowing the AI to learn more complex patterns than just simple additions and multiplications.\n",
        "    *   **`nn.Linear(4 * n_embd, n_embd)`**: This is a 'thought compressor'. After expanding and thinking, it brings the word's code back to its original size. It's like distilling the refined meaning of the word.\n",
        "    *   **`nn.Dropout(dropout)`**: Just like before, this randomly turns off some connections to prevent the AI from overthinking or memorizing specific examples too much.\n",
        "\n",
        "**`forward` (Processing the words):**\n",
        "*   When `FeedForward` receives a word's processed code (`x`), it simply passes it through the sequence of layers (`self.net`) it set up. This allows the AI to perform a quick, independent 'analysis' on each word's representation before moving on.\n",
        "\n",
        "In short, this `FeedForward` block helps the AI enrich the understanding of each word by first expanding its representation, applying a non-linear transformation, and then compressing it back, making the word's meaning more robust and informative."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------"
      ],
      "metadata": {
        "id": "Wqmj7_9MP8Jt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, n_embd, n_head, block_size, dropout):\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.attn = CausalSelfAttention(n_embd, n_head, block_size, dropout)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "        self.ff = FeedForward(n_embd, dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln1(x))  # residual connection\n",
        "        x = x + self.ff(self.ln2(x))    # residual connection\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "_vcciawdP8rt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## The `Block`: One Full Thinking Unit\n",
        "\n",
        "This code defines a **`Block`** — a core building unit in the model.  \n",
        "If you’re thinking in Transformer terms, this is one complete **reasoning step** in the network.\n",
        "\n",
        "A `Block` combines:\n",
        "- **Causal Self-Attention** (context awareness)\n",
        "- **FeedForward networks** (per-token reasoning)\n",
        "- **Layer Normalisation** (stability)\n",
        "- **Residual connections** (information preservation)\n",
        "\n",
        "Together, these make the model deep *without* making it fragile.\n",
        "\n",
        "---\n",
        "\n",
        "## What happens inside the Block\n",
        "\n",
        "### 1. `__init__` — wiring the machinery\n",
        "\n",
        "The constructor sets up everything the block needs:\n",
        "\n",
        "- **Inputs**\n",
        "  - `n_embd`: embedding size (how rich each token’s representation is)\n",
        "  - `n_head`: number of attention heads\n",
        "  - `block_size`: maximum context length\n",
        "  - `dropout`: regularisation strength\n",
        "\n",
        "- **Components**\n",
        "  - `ln1 = nn.LayerNorm(n_embd)`  \n",
        "    Normalises the input before attention. This keeps activations well-behaved and training stable.\n",
        "  - `attn = CausalSelfAttention(...)`  \n",
        "    Lets each token selectively attend to relevant *past* tokens.\n",
        "  - `ln2 = nn.LayerNorm(n_embd)`  \n",
        "    Another normalisation pass, this time before deeper processing.\n",
        "  - `ff = FeedForward(...)`  \n",
        "    Applies non-linear, per-token transformation — essentially the model “thinking harder” about each word.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. `forward` — doing the actual work\n",
        "\n",
        "This is where the data flows:\n",
        "\n",
        "- **Attention + residual**\n",
        "  ```python\n",
        "  x = x + self.attn(self.ln1(x))\n",
        "\n",
        "\n",
        "- **FeedForward + residual**\n",
        "\n",
        "  ```  \n",
        "  x = x + self.ff(self.ln2(x))  \n",
        "  \n",
        "  ```\n",
        "    Output is normalised again\n",
        "\n",
        "    Passed through the FeedForward network\n",
        "\n",
        "    Added back to preserve the signal\n",
        "\n",
        "------\n",
        "\n",
        "### Why this design works\n",
        "\n",
        "A Block:\n",
        "\n",
        "Stabilises signals with layer normalisation\n",
        "\n",
        "Understands context with attention\n",
        "\n",
        "Deepens meaning with FeedForward layers\n",
        "\n",
        "Preserves information using residual connections\n",
        "\n",
        "Stack many of these blocks, and you get a model that is deep, expressive, and trainable — exactly what modern language models rely on."
      ],
      "metadata": {
        "id": "HGl0uKJxRjqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SmallLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size, block_size, n_embd, n_head, n_layer, dropout):\n",
        "        super().__init__()\n",
        "        self.block_size = block_size\n",
        "\n",
        "        # Token + position embeddings\n",
        "        self.token_emb = nn.Embedding(vocab_size, n_embd)\n",
        "        self.pos_emb   = nn.Embedding(block_size, n_embd)\n",
        "\n",
        "        # Transformer blocks\n",
        "        self.blocks = nn.Sequential(*[\n",
        "            Block(n_embd, n_head, block_size, dropout) for _ in range(n_layer)\n",
        "        ])\n",
        "\n",
        "        self.ln_f = nn.LayerNorm(n_embd)\n",
        "        self.head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # positions: 0..T-1\n",
        "        pos = torch.arange(0, T, device=idx.device)\n",
        "\n",
        "        x = self.token_emb(idx) + self.pos_emb(pos)  # (B, T, n_embd)\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.head(x)                        # (B, T, vocab_size)\n",
        "\n",
        "        # If targets given, compute loss\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            loss = F.cross_entropy(\n",
        "                logits.view(-1, vocab_size),\n",
        "                targets.view(-1)\n",
        "            )\n",
        "\n",
        "        return logits, loss\n"
      ],
      "metadata": {
        "id": "l6azfTYTQRD6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## `SmallLanguageModel`: A Minimal Transformer Language Model\n",
        "\n",
        "This class defines **`SmallLanguageModel`**, a compact but complete Transformer-based language model. It takes token indices as input and predicts the next token at every position.\n",
        "\n",
        "Conceptually, it is made of:\n",
        "- Token and position embeddings\n",
        "- A stack of Transformer `Block`s\n",
        "- A final normalisation and projection to vocabulary logits\n",
        "\n",
        "Despite being “small”, this structure mirrors the core design of modern large language models.\n",
        "\n",
        "---\n",
        "\n",
        "## Model structure\n",
        "\n",
        "### `__init__` — building the model\n",
        "\n",
        "The constructor assembles all major components:\n",
        "\n",
        "- **Parameters**\n",
        "  - `vocab_size`: number of unique tokens in the vocabulary\n",
        "  - `block_size`: maximum context length\n",
        "  - `n_embd`: embedding dimension\n",
        "  - `n_head`: number of attention heads per block\n",
        "  - `n_layer`: number of Transformer blocks\n",
        "  - `dropout`: regularisation strength\n",
        "\n",
        "- **Embeddings**\n",
        "  - `self.token_emb = nn.Embedding(vocab_size, n_embd)`  \n",
        "    Converts token IDs into dense vector representations.\n",
        "  - `self.pos_emb = nn.Embedding(block_size, n_embd)`  \n",
        "    Encodes positional information so the model knows token order.\n",
        "\n",
        "- **Transformer stack**\n",
        "  - `self.blocks = nn.Sequential(...)`  \n",
        "    A stack of `n_layer` identical `Block`s, each refining the representation using attention and FeedForward layers.\n",
        "\n",
        "- **Output layers**\n",
        "  - `self.ln_f = nn.LayerNorm(n_embd)`  \n",
        "    Final normalisation before prediction.\n",
        "  - `self.head = nn.Linear(n_embd, vocab_size)`  \n",
        "    Projects embeddings to vocabulary-sized logits.\n",
        "\n",
        "---\n",
        "\n",
        "## Forward pass\n",
        "\n",
        "### `forward(self, idx, targets=None)`\n",
        "\n",
        "- **Inputs**\n",
        "  - `idx`: token indices of shape `(B, T)`\n",
        "  - `targets` (optional): ground-truth tokens for loss computation\n",
        "\n",
        "- **Step-by-step flow**\n",
        "\n",
        "  - Extract batch and sequence length:\n",
        "    ```python\n",
        "    B, T = idx.shape\n",
        "    ```\n",
        "\n",
        "  - Create positional indices:\n",
        "    ```python\n",
        "    pos = torch.arange(0, T, device=idx.device)\n",
        "    ```\n",
        "\n",
        "  - Combine token and position embeddings:\n",
        "    ```python\n",
        "    x = self.token_emb(idx) + self.pos_emb(pos)\n",
        "    ```\n",
        "    This produces a `(B, T, n_embd)` tensor representing both meaning and position.\n",
        "\n",
        "  - Pass through Transformer blocks:\n",
        "    ```python\n",
        "    x = self.blocks(x)\n",
        "    ```\n",
        "\n",
        "  - Apply final normalisation:\n",
        "    ```python\n",
        "    x = self.ln_f(x)\n",
        "    ```\n",
        "\n",
        "  - Project to vocabulary logits:\n",
        "    ```python\n",
        "    logits = self.head(x)\n",
        "    ```\n",
        "    Shape: `(B, T, vocab_size)`\n",
        "\n",
        "---\n",
        "\n",
        "## Loss computation (optional)\n",
        "\n",
        "If `targets` are provided, the model computes cross-entropy loss:\n",
        "\n",
        "```python\n",
        "loss = F.cross_entropy(\n",
        "    logits.view(-1, vocab_size),\n",
        "    targets.view(-1)\n",
        ")\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "## Output\n",
        "\n",
        "```\n",
        "return logits, loss\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "#### logits: raw predictions for each token\n",
        "\n",
        "#### loss: training loss (only during training)\n",
        "\n",
        "----\n",
        "\n",
        "## Summary\n",
        "\n",
        "SmallLanguageModel embeds tokens, injects positional information, refines representations through stacked Transformer blocks, and predicts the next token at every position. It is a minimal yet faithful implementation of a modern autoregressive language model"
      ],
      "metadata": {
        "id": "HKsIGXt-TVHy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ta2e-UGDTgCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SmallLanguageModel(\n",
        "    vocab_size=vocab_size,\n",
        "    block_size=block_size,\n",
        "    n_embd=n_embd,\n",
        "    n_head=n_head,\n",
        "    n_layer=n_layer,\n",
        "    dropout=dropout\n",
        ").to(device)\n",
        "\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "for step in range(steps):\n",
        "    model.train()\n",
        "    x, y = get_batch(\"train\")\n",
        "\n",
        "    logits, loss = model(x, y)\n",
        "\n",
        "    optim.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "    if step % 100 == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            vx, vy = get_batch(\"val\")\n",
        "            _, vloss = model(vx, vy)\n",
        "        print(f\"step {step} | train loss {loss.item():.4f} | val loss {vloss.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcufgVIVQTyz",
        "outputId": "3f1d3989-28ef-4af9-a561-00739ec05173"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0 | train loss 10.9717 | val loss 10.9417\n",
            "step 100 | train loss 5.7057 | val loss 7.9696\n",
            "step 200 | train loss 4.1628 | val loss 7.5968\n",
            "step 300 | train loss 3.0546 | val loss 8.4096\n",
            "step 400 | train loss 2.1384 | val loss 9.2352\n",
            "step 500 | train loss 1.7609 | val loss 8.5423\n",
            "step 600 | train loss 1.2647 | val loss 9.3160\n",
            "step 700 | train loss 0.9250 | val loss 9.3784\n",
            "step 800 | train loss 0.5399 | val loss 9.1878\n",
            "step 900 | train loss 0.3689 | val loss 9.9592\n",
            "step 1000 | train loss 0.2546 | val loss 9.5096\n",
            "step 1100 | train loss 0.2093 | val loss 10.3400\n",
            "step 1200 | train loss 0.1582 | val loss 10.2176\n",
            "step 1300 | train loss 0.1195 | val loss 10.1162\n",
            "step 1400 | train loss 0.1250 | val loss 9.9437\n",
            "step 1500 | train loss 0.1185 | val loss 10.0561\n",
            "step 1600 | train loss 0.0991 | val loss 10.6218\n",
            "step 1700 | train loss 0.0957 | val loss 10.5738\n",
            "step 1800 | train loss 0.0679 | val loss 9.8559\n",
            "step 1900 | train loss 0.0937 | val loss 10.7936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e32acb6"
      },
      "source": [
        "---\n",
        "\n",
        "This code block is where we bring our `SmallLanguageModel` to life and teach it to understand language. It sets up the model, prepares how it will learn, and then runs a training process.\n",
        "\n",
        "### 1. **`model = SmallLanguageModel(...)`** (Creating the AI):\n",
        "*   This line creates an actual instance of our `SmallLanguageModel` using all the settings we defined earlier (like `vocab_size`, `block_size`, `n_embd`, `n_head`, `n_layer`, `dropout`).\n",
        "*   `.to(device)`: This moves the entire model to the selected device, either the super-fast 'cuda' (GPU) if available, or the 'cpu' (main processor).\n",
        "\n",
        "### 2. **`optim = torch.optim.AdamW(model.parameters(), lr=lr)`** (The Learning Coach):\n",
        "*   This sets up an 'optimizer' named `AdamW`. Think of this as the coach who helps the AI adjust its 'brain' to learn better.\n",
        "*   `model.parameters()`: These are all the adjustable parts of the AI's brain that the coach will help tune.\n",
        "*   `lr=lr`: This is the 'learning rate' (a small number like 0.0003) which tells the coach how big of a step to take when making adjustments.\n",
        "\n",
        "### 3. **`for step in range(steps):`** (The Training Sessions):\n",
        "*   This starts the main training loop, which will run for `steps` (e.g., 2000) times.\n",
        "\n",
        "    *   **`model.train()`**: This puts the model in 'training mode'. Some layers (like `dropout`) behave differently during training.\n",
        "\n",
        "    *   **`x, y = get_batch(\"train\")`**: We get a batch of training data. `x` is the input (the text the model sees), and `y` is the target (what the model should predict next).\n",
        "\n",
        "    *   **`logits, loss = model(x, y)`**: The model looks at `x`, tries to predict `y`, and then calculates how wrong it was. This 'how wrong' is called the `loss`.\n",
        "\n",
        "    *   **`optim.zero_grad(set_to_none=True)`**: Before the coach makes new adjustments, it clears out any old instructions from the previous step.\n",
        "\n",
        "    *   **`loss.backward()`**: This is where the AI figures out how each part of its 'brain' contributed to the `loss` (how wrong it was). It calculates 'gradients'.\n",
        "\n",
        "    *   **`optim.step()`**: The coach uses these gradients to update the AI's brain, making it a little better at predicting.\n",
        "\n",
        "    *   **`if step % 100 == 0:`** (Checking Progress):\n",
        "        *   Every 100 steps, the model pauses training to check how well it's doing.\n",
        "        *   **`model.eval()`**: It switches to 'evaluation mode', where `dropout` layers are turned off because we want consistent predictions."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def generate(model, prompt: str, max_new_tokens=80, temperature=1.0, top_k=50):\n",
        "    model.eval()\n",
        "\n",
        "    idx = torch.tensor(tokenizer.encode(prompt), dtype=torch.long, device=device).unsqueeze(0)\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "        # Keep only last block_size tokens (context limit)\n",
        "        idx_cond = idx[:, -block_size:]\n",
        "\n",
        "        logits, _ = model(idx_cond)\n",
        "        logits = logits[:, -1, :] / temperature  # last position\n",
        "\n",
        "        # top-k sampling (optional, helps quality)\n",
        "        if top_k is not None:\n",
        "            v, _ = torch.topk(logits, top_k)\n",
        "            logits[logits < v[:, [-1]]] = -float(\"inf\")\n",
        "\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        next_id = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "        idx = torch.cat([idx, next_id], dim=1)\n",
        "\n",
        "    return tokenizer.decode(idx[0].tolist())\n",
        "\n",
        "print(generate(model, \"Xasan \"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLnG0GT-Rec7",
        "outputId": "887a01f1-b268-4b51-a6ee-4c2d16010cbb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Xasan  People former Chief of Staff and Benadir regional administration in an effort to avail itself of the occasion to plant as the occasion to plant as the U.S. They also announced that the top Somali would not attend the establishment of the Somali Film Council.\n",
            "\n",
            "\n",
            "According to Hassan, the Somali federal government delegation is scheduled to meet with its U.S. partners to discuss further ways to promote\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "This code defines the **`generate` function**, which is responsible for taking a starting prompt and having our trained `SmallLanguageModel` creatively write new text based on it.\n",
        "\n",
        "Think of it like giving the AI a sentence beginning and asking it to complete the story.\n",
        "\n",
        "### How it works (simplified):\n",
        "\n",
        "**`@torch.no_grad()`**: This is a special instruction that tells PyTorch we don't need to calculate gradients during this process. Since we're not training, this saves memory and makes text generation faster.\n",
        "\n",
        "**`def generate(model, prompt: str, max_new_tokens=80, temperature=1.0, top_k=50):`**\n",
        "*   **`model`**: This is our trained `SmallLanguageModel`.\n",
        "*   **`prompt`**: This is the starting text (e.g., \"Xasan \") that we give the model.\n",
        "*   **`max_new_tokens`**: The maximum number of new words or parts of words the model should generate (default is 80).\n",
        "*   **`temperature`**: This controls how 'creative' or 'random' the generated text is. A lower temperature (e.g., 0.5) makes the output more focused and predictable, while a higher temperature (e.g., 1.5) makes it more diverse and surprising.\n",
        "*   **`top_k`**: This limits the model's choices for the next word to only the `k` most probable options. This often helps produce more coherent and relevant text.\n",
        "\n",
        "**Step-by-step generation process:**\n",
        "\n",
        "1.  **`model.eval()`**: Puts the model in 'evaluation mode', so it behaves consistently without things like dropout.\n",
        "\n",
        "2.  **`idx = torch.tensor(tokenizer.encode(prompt), ...)`**: The initial `prompt` text is converted into numbers (tokens) that the model understands. It's also prepared as a PyTorch tensor and sent to the correct device (CPU or GPU).\n",
        "\n",
        "3.  **`for _ in range(max_new_tokens):`**: This loop runs for each new token we want to generate.\n",
        "\n",
        "    *   **`idx_cond = idx[:, -block_size:]`**: The model can only look at a certain number of previous tokens (`block_size`) for context. This line makes sure we only feed the most recent relevant tokens into the model.\n",
        "\n",
        "    *   **`logits, _ = model(idx_cond)`**: The model takes the current context (`idx_cond`) and predicts what the *next* word should be. `logits` are the raw scores for each possible word in its vocabulary.\n",
        "\n",
        "    *   **`logits = logits[:, -1, :] / temperature`**: We take the predictions for the *very last* word in the context and apply the `temperature` to them. This influences the randomness of the next word selection.\n",
        "\n",
        "    *   **`if top_k is not None: ...`**: If `top_k` is set, it filters the `logits` so that only the top `k` most likely words have a chance of being picked. All other words get a score of negative infinity, meaning they will never be chosen.\n",
        "\n",
        "    *   **`probs = F.softmax(logits, dim=-1)`**: The `logits` (raw scores) are turned into `probs` (probabilities), where all probabilities add up to 1.\n",
        "\n",
        "    *   **`next_id = torch.multinomial(probs, num_samples=1)`**: Based on these probabilities, the model randomly picks *one* word (token ID) to be the next word. More probable words are more likely to be chosen.\n",
        "\n",
        "    *   **`idx = torch.cat([idx, next_id], dim=1)`**: The newly generated word's ID is added to our sequence of tokens, extending the text.\n",
        "\n",
        "4.  **`return tokenizer.decode(idx[0].tolist())`**: After generating all the new tokens, the entire sequence of token IDs is converted back into human-readable text and returned.\n",
        "\n",
        "In essence, the `generate` function allows the trained language model to act like a text continuation engine, creatively extending a given prompt into a longer passage of text.\n"
      ],
      "metadata": {
        "id": "OTCU67IlWos6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yvNVdxTQVymx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}